import { normalizeText } from "../core/text-utils";

const createNormalizedSet = (words: string[]): Set<string> => {
  return new Set(words.map(normalizeText));
};

const rawStopwords = [
  "a",
  "an",
  "the",
  "very",
  "too",
  "own",
  "same",
  "some",
  "few",
  "more",
  "most",
  "all",
  "just",
  "here",
  "there",
  "this",
  "these",
  "those",
  "i",
  "you",
  "he",
  "she",
  "it",
  "we",
  "they",
  "simple",
  "basic",
  "clear",
  "obvious",
  "important",
  "necessary",
  "complex",
  "specific",
  "general",
  "appropriate",
  "relevant",
  "complete",
  "really",
  "basically",
  "literally",
  "actually",
  "simply",
  "usually",
  "generally",
  "essentially",
  "mostly",
];

export const STOPWORDS = createNormalizedSet(rawStopwords);

const rawPoliteness = [
  "please",
  "kindly",
  "could you",
  "would you",
  "can you",
  "may i",
  "could i",
  "would i",
  "i would like",
  "i need",
  "i want",
  "if possible",
  "if you can",
  "thank you",
  "thanks",
  "appreciate it",
  "i appreciate",
  "many thanks",
];

export const POLITENESS_PHRASES = createNormalizedSet(rawPoliteness);

const rawConnectors = [
  "therefore",
  "thus",
  "hence",
  "consequently",
  "as a result",
  "for this reason",
  "because of this",
  "moreover",
  "furthermore",
  "additionally",
  "also",
  "in addition",
  "besides",
  "likewise",
  "similarly",
  "in the same way",
  "equally",
  "that is",
  "in other words",
  "namely",
  "for example",
  "for instance",
  "such as",
];

export const CONNECTORS = createNormalizedSet(rawConnectors);
